
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MF3D Background &#8212; MF3D 1.0 documentation</title>
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/css/mf3d.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="MF3D Release 1" href="MF3D-Release-1.html" />
    <link rel="prev" title="MF3D Overview" href="MF3D-Overview.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="MF3D-Release-1.html" title="MF3D Release 1"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="MF3D-Overview.html" title="MF3D Overview"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">MF3D 1.0 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">MF3D Background</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="mf3d-background">
<h1>MF3D Background<a class="headerlink" href="#mf3d-background" title="Permalink to this headline">¶</a></h1>
<p>Why are neuroscientists creating virtual reality monkeys? The answer requires a brief history of the field of social neuroscience and the importance of the macaque monkey as an animal model for understanding the human brain and psychiatric disorders.</p>
<div class="section" id="studying-the-social-primate-brain">
<h2>Studying the social primate brain<a class="headerlink" href="#studying-the-social-primate-brain" title="Permalink to this headline">¶</a></h2>
<div class="figure align-right" id="id6" style="width: 30%">
<a class="reference internal image-reference" href="_images/NHPSpeciesPieChart.png"><img alt="Primate species in research" src="_images/NHPSpeciesPieChart.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">While non-human primates (NHPs) make up only a very small fraction of animals used in biomedical research, the majority of NHPs used in research are Rhesus macaques. Data from <a class="reference external" href="https://orip.nih.gov/sites/default/files/508%20NHP%20Evaluation%20and%20Analysis%20Final%20Report%20-%20Part%201.pdf">NIH (2017)</a>.</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
<p>In order to advance our limited understanding of how complex primate brains
like ours work to coordinate social interactions, we need animal models that
allow us to ethically study the neural correlates at the cellular level.
Non-human primates represent a crucial resource in this endeavor, and the <a class="reference external" href="https://en.wikipedia.org/wiki/Rhesus_macaque">Rhesus
monkey</a> (<em>Macaca mulatta</em>) - a species of Old World monkey - is one of the most promising and popular (Figure 1; <a class="reference external" href="https://orip.nih.gov/sites/default/files/508%20NHP%20Evaluation%20and%20Analysis%20Final%20Report%20-%20Part%201.pdf">NIH, 2017</a>).</p>
<div class="figure align-left" id="id7" style="width: 30%">
<a class="reference internal image-reference" href="_images/MacaqueGroup_CNPRC.jpg"><img alt="Rhesus macaques at CNPRC" src="_images/MacaqueGroup_CNPRC.jpg" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Group-housed Rhesus macaques (image from <a class="reference external" href="https://cnprc.ucdavis.edu/how-researchers-are-protecting-non-human-primates-from-measles-outbreak/">CNPRC</a>)</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
<p>In the wild, Rhesus macaques have the second largest territorial range of any primate on earth (after humans). They live in large troops composed of up to hundreds of individuals, which are organized by strict social hierarchies and governed by rules of social interaction. They rely predominantly on their high acuity vision for gathering information about the intentions and internal states of their conspecifics. The similarity of these macaque traits to our own make the macaque the best available animal model for understanding the neural processes underlying complex social behaviors that are unique to primates like us.</p>
</div>
<div class="section" id="face-processing-in-the-macaque-brain">
<h2>Face processing in the macaque brain<a class="headerlink" href="#face-processing-in-the-macaque-brain" title="Permalink to this headline">¶</a></h2>
<div class="figure align-right" id="id8" style="width: 40%">
<a class="reference internal image-reference" href="_images/Gross1984.png"><img alt="Gross et al., 1972 &amp; 1984" src="_images/Gross1984.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Peri-stimulus time histograms (PSTHs) show changes in firing rate of a neuron in inferotemproal cortex that is sensitive to changes in the head angle of the macaque presented to the subject as photographic stimuli (<a class="reference external" href="https://doi.org/10.1523/JNEUROSCI.04-08-02051.1984">Desimone et al., 1984</a>).</span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</div>
<p>Neural responses to images of faces in the macaque brain were first reported by <a class="reference external" href="https://doi.org/10.1152/jn.1972.35.1.96">Gross et al. (1972)</a>. The approach of recording extracellular spiking activity during visual stimulation of the anesthetized monkey followed that of <a class="reference external" href="https://doi.org/10.1113/jphysiol.1968.sp008455">Hubel &amp; Wiesel (1968)</a>. Subsequent electrophysiology studies revealed that many of these neurons in the macaque superior temporal sulcus (STS) are sensitive to specific types of facial information, including head and eye gaze direction, identity, and facial expression (<a class="reference external" href="https://doi.org/10.1007/BF00239352">Perrett et al., 1982</a>; <a class="reference external" href="https://doi.org/10.1098/rspb.1985.0003">1985</a>; <a class="reference external" href="10.1016/s0166-4328(89)80054-3">Hasselmo, Rolls &amp; Baylis, 1989</a>).</p>
<div class="figure align-left" id="id9" style="width: 25%">
<a class="reference internal image-reference" href="_images/Freiwald_patches.jpg"><img alt="Macaque fMRI" src="_images/Freiwald_patches.jpg" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Regions of ‘face selective’ voxels in the macaque brain localized using functional magnetic resonance imaging (fMRI) suggest a brain network (<a class="reference external" href="https://doi.org/10.1126/science.aan1139">Landi &amp; Freiwald, 2017</a>).</span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</div>
<p>The development of non-invasive functional magnetic resonance imaging (fMRI) in the 1990s lead to the discovery of face selective regions of ventral visual cortex in humans (<a class="reference external" href="https://doi.org/10.1523/JNEUROSCI.17-11-04302.1997">Kanwisher et al., 1997</a>) and subsequently the discovery that face-selective neurons were also clustered together in specific regions of the macaque inferotemporal (IT) cortex (<a class="reference external" href="https://doi.org/10.1038/nn1111">Tsao et al., 2003</a>; <a class="reference external" href="https://doi.org/10.1126/science.1119983">2006</a>; <a class="reference external" href="https://doi.org/10.1073/pnas.0502605102">Pinsk et al., 2005</a>), prefrontal cortex (<a class="reference external" href="https://doi.org/10.1038/nn.2158">Tsao et al., 2008</a>) and medial temporal lobe (<a class="reference external" href="https://doi.org/10.1126/science.aan1139">Landi &amp; Freiwald, 2017</a>).</p>
</div>
<div class="section" id="limitations-of-traditional-vision-neuroscience-approach">
<h2>Limitations of traditional vision neuroscience approach<a class="headerlink" href="#limitations-of-traditional-vision-neuroscience-approach" title="Permalink to this headline">¶</a></h2>
<div class="figure align-right" id="id10" style="width: 40%">
<a class="reference external image-reference" href="https://www.cell.com/cms/10.1016/j.cub.2014.08.063/attachment/97abaa03-5af9-440a-86d0-ebfcde401546/mmc4.mp4"><img alt="_images/Mosher2015.png" src="_images/Mosher2015.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Natural video stimuli used by Mosher and colleagues (2015) revealed that some amygdala neurons are sensitive to whether the subject is looking at the eyes of another animal. Click image to view movie.</span><a class="headerlink" href="#id10" title="Permalink to this image">¶</a></p>
</div>
<p>The reductionist approach that has proven so successful for understanding the neurophysiological basis of visual processing in early visual areas, typically relies on simplified, abstract or artificial stimuli in order to allow for systematic, parameterized testing along stimulus dimensions of interest. However, the artificial nature of these experimental paradigms raises questions of their relevance to the types of visual experiences that the brain naturally encounters. This tension between rigorous control and ethological validity is perhaps most conspicuous in trying to understand the visual processing of social cues, to which much of the primate brain appears dedicated.</p>
<p>Consequently, scientists have more recently begun exploring alternative approaches that utilize more complex, ethologically valid visual stimulation paradigms (<a class="reference external" href="https://doi.org/10.1126/science.1089506">Hasson et al., 2003</a>; <a class="reference external" href="https://doi.org/10.1016/j.cub.2014.08.063">Mosher, Zimmerman &amp; Gothard, 2014</a>; <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2015.01.012">Russ &amp; Leopold, 2015</a>; <a class="reference external" href="https://doi.org/10.1523/JNEUROSCI.3825-14.2015">McMahon et al., 2015</a>; <a class="reference external" href="https://doi.org/10.1016/j.neuron.2017.07.014">Park et al., 2017</a>; <a class="reference external" href="https://doi.org/10.1126/science.aam6383">Sliwa &amp; Freiwarld, 2017</a>). However, the trade-off of using ‘natural’ video stimuli is the loss of experimental control. While the visual and semantic content of video footage containing human actors is at least partially under the control of the director, natural movies of macaque subjects cannot be easily choreographed to address specific research questions.</p>
</div>
<div class="section" id="development-of-macaque-avatars">
<h2>Development of Macaque Avatars<a class="headerlink" href="#development-of-macaque-avatars" title="Permalink to this headline">¶</a></h2>
<div class="figure align-left" id="id11" style="width: 40%">
<a class="reference internal image-reference" href="_images/MacaqueAvatarsFig.png"><img alt="Macaque avatars" src="_images/MacaqueAvatarsFig.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text"><strong>Developmental history of digital macaque avatars. A.</strong> <a class="reference external" href="https://doi.org/10.1073/pnas.0910063106">Steckenfinger &amp; Ghazanfar, 2009</a> <strong>B.</strong> <a class="reference external" href="https://doi.org/10.1073/pnas.1214956110">Ghazanfar et al., 2013</a> <strong>C.</strong> Artist: <a class="reference external" href="https://www.artstation.com/timrozek">Tim Mrozek</a> (<a class="reference external" href="https://doi.org/10.1111/desc.12207">Paukner et al., 2014</a>; <a class="reference external" href="https://doi.org/10.1038/srep19669">Simpson et al., 2016</a>) <strong>D.</strong> Artist: <a class="reference external" href="https://www.3dminfographie.com/en/">Damien Montelliard</a> (<a class="reference external" href="https://doi.org/10.1101/758458">Wilson et al., 2019</a>) <strong>E.</strong> (<a class="reference external" href="https://doi.org/10.1523/ENEURO.0524-19.2020">Siebert et al., 2020</a>) <strong>F.</strong> Artist: <a class="reference external" href="https://www.kellybullockart.com/macaquemonkey">Kelly Bullock, 2019</a> (<a class="reference external" href="http://martinezlab.robarts.ca/">Martinez-Trujillo lab</a>, unpublished) <strong>G.</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Barbary_macaque">Barbary macaque (M.sylvanus)</a>, by artist <a class="reference external" href="https://area.autodesk.com/gallery/barbary-macaque/">Shariq Altaf, 2018</a>. <strong>H.</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Japanese_macaque">Japanese macaque (M.fuscata)</a> by artist <a class="reference external" href="www.andreholzmeister.com/primate_pages">Andre Holzmeister, 2017</a>. <strong>I.</strong> Japanese macaque by studio <a class="reference external" href="www.kleosanimation.com">Kleos Animation, 2018</a>.</span><a class="headerlink" href="#id11" title="Permalink to this image">¶</a></p>
</div>
<p>Digital macaque ‘avatars’ have been used in behavioral and neuroscience research for over a decade (<span class="xref std std-ref">Figure 1</span>). This approach has typically involved a trade-off between ethological validity (i.e. how natural and/or ‘real’ the visual stimulus appears to the subject) and experimental control. Indeed, an early study concluded that macaque subjects may experience a perceptual phenomenon known as the ‘uncanny valley’, whereby semi-realistic artificial representations of faces elicit more negative emotional responses than either real or obviously artificial faces (<a class="reference external" href="https://doi.org/10.1073/pnas.0910063106">Steckenfinger &amp; Ghazanfar, 2009</a>).</p>
<p>Since the earliest uses of macaque avatars (<span class="xref std std-ref">Figure 1A</span>), technological advances in graphic processing power and decreases in cost have lead to increased accessibility and photorealistic quality of rendering for complex particle systems (such as hair and fur) and naturalistic lighting (such as subsurface scattering). Given a studio budget, state of the art CGI is now almost <a class="reference external" href="https://www.youtube.com/watch?v=HjHiC0mt4Ts">indistinguishable from video</a>, while even low-budget projects utilizing open-source tools such as <a class="reference external" href="www.blender.org">Blender</a> can now achieve high-quality results.</p>
<p>Despite these technological advances, the time and cost of employing skilled digital professionals to generate realistic 3D models of macaques can be prohibitive for lab budgets. The duplication of these efforts across many labs who opt not to share their intellectual property is ultimately a waste of resources for the research community. MF3D is the first ever publicly available macaque avatar resource for the scientific research community.</p>
</div>
<div class="section" id="virtual-reality-ethologically-validity-and-experimental-control">
<h2>Virtual Reality: ethologically validity and experimental control<a class="headerlink" href="#virtual-reality-ethologically-validity-and-experimental-control" title="Permalink to this headline">¶</a></h2>
<div class="figure align-right" id="id12" style="width: 50%">
<a class="reference internal image-reference" href="_images/MF3D_SceneDemo.png"><img alt="MF3D avatar in a naturalistic VR" src="_images/MF3D_SceneDemo.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">An example frame of the MF3D avatar inserted into a naturalistic virtual environment, rendered with Blender’s Cycles engine.</span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</div>
<p>While the use of macaque avatars rendered in isolation is the logical extension of the traditional visual neuroscience approach, a major benefit of the flexibility provided by a digital avatar is the ability to embed it in more naturalistic virtual environments. This can take the form of either offline rendered film-like realistic scenes, or real-time rendered computer game-like scenes. These approaches offer the ability to address a range of research questions that it would not be possible to test using traditional video stimuli or real-life interactions between animals.</p>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/MF3D_Logo_black.svg" alt="Logo"/>
            </a></p>
<h3><a href="index.html">Table of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="MF3D-Overview.html">Overview</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Background</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#studying-the-social-primate-brain">Studying the social primate brain</a></li>
<li class="toctree-l2"><a class="reference internal" href="#face-processing-in-the-macaque-brain">Face processing in the macaque brain</a></li>
<li class="toctree-l2"><a class="reference internal" href="#limitations-of-traditional-vision-neuroscience-approach">Limitations of traditional vision neuroscience approach</a></li>
<li class="toctree-l2"><a class="reference internal" href="#development-of-macaque-avatars">Development of Macaque Avatars</a></li>
<li class="toctree-l2"><a class="reference internal" href="#virtual-reality-ethologically-validity-and-experimental-control">Virtual Reality: ethologically validity and experimental control</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="MF3D-Release-1.html">MF3D Release 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="MF3D-Release-2.html">MF3D Release 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="MF3D-Stimulus-Editor.html">MF3D Tools - Stimulus Editor</a></li>
<li class="toctree-l1"><a class="reference internal" href="MF3D-Video-Parameter-Estimation-GUI.html">MF3D Tools - Video Parameter GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="MF3D-Parameterizing-anatomical-variations.html">Methods - Face Space</a></li>
<li class="toctree-l1"><a class="reference internal" href="MF3D-Research.html">Published Research</a></li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="MF3D-Overview.html"
                        title="previous chapter">MF3D Overview</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="MF3D-Release-1.html"
                        title="next chapter">MF3D Release 1</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="MF3D-Release-1.html" title="MF3D Release 1"
             >next</a> |</li>
        <li class="right" >
          <a href="MF3D-Overview.html" title="MF3D Overview"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">MF3D 1.0 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">MF3D Background</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Aidan Murphy.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.1.1.
    </div>
  </body>
</html>